【】Spark与MapReduce区别
MapReduce：基于磁盘进行计算，中间计算的结果都是存储在磁盘中，每次计算都是从磁盘中来加载数据。
    （一次 MapReduce 运算之后,会将数据的运算结果从内存写入到磁盘中,第二次 Mapredue 运算时在从磁盘中读取数据,所以其瓶颈在2次运算间的多余 IO 消耗）
    Hadoop 的 Map 和 reduce 之间的 shuffle 需要 sort。

Spark：Spark 则是将数据一直缓存在内存中,直到计算得到最后的结果,再将结果写入到磁盘,所以多次运算的情况下, Spark 是比较快的.
    当内存不足时，可以溢出到磁盘上。

【】spark介绍
Spark 是使用 scala 实现的基于内存计算的大数据开源集群计算环境.

Spark 集群中,分为 Master 节点与 worker 节点,,其中 Master 节点上常驻 Master 守护进程和 Driver 进程,
Master 负责将串行任务变成可并行执行的任务集Tasks, 同时还负责出错问题处理等,而 Worker 节点上常驻 Worker 守护进程,
Master 节点与 Worker 节点分工不同, Master 负载管理全部的 Worker 节点,而 Worker 节点负责执行任务.

Spark 支持不同的运行模式,包括Local, Standalone,Mesoses,Yarn 模式.不同的模式可能会将 Driver 调度到不同的节点上执行.

ps:
运行程序前得安装spark环境，由于是使用Scala编写的，仅是提供了java API的接口，具体的执行还是得Scala程序来运行，因此需要先安装。---验证不安装也可以本地运行


【】运行方式
方式1：spark-submit --class com.xxxx.App xxxxx.jar --master local[3]  --验证OK

【】SparkSQL
SparkSQL可以理解为在原生的RDD上做的一层封装，通过SparkSQL可以在scala和java中写SQL语句，Spark SQL也可以用来从Hive中读取数据，
并将结果作为Dataset/DataFrame返回。简单来讲，SparkSQL可以让我们像写SQL一样去处理内存中的数据。
它是用来处理结构化的数据，例如具有schema结构的数据，json, parquet, avro, csv格式的。
比如txt的等非格式化数据可以通过spark转成指定格式化的数据，再通过sql进行查询。

通过spark sql ，可以使用SQL 或者 HQL 来查询数据，查询结果以Dataset/DataFrame 的形式返回
它支持多种数据源，如Hive 表、Parquet 以及 JSON 等
它支持开发者将SQL 和传统的RDD 变成相结合

产生背景
我们可以直接通过写sql来分析大数据中的数据。
hive是把sql翻译成mapreduce作业，mapreduce执行效率是不高的（当数据量比较大，执行时间可能十几个小时）


【问题】
1、mp和spark在各个环境如何来运行--本地、机群等方式
    spark机群模式运行原理及一个任务如何来执行？？
    yarn模式具体操作？？
2、好的场景使用spark来构建项目？
3、spark等计算框架原理思考贯通？



【】为什么Spark比MapReduce快？
Spark计算比MapReduce快的根本原因在于DAG计算模型。（DAG实际是一个RDD关系图），DAG相比Hadoop的MapReduce在大多数情况下可以减少shuffle（洗牌）次数-比如数据转换等。
Spark是基于内存的计算，所以快，这也不是主要原因，要对数据做计算，必然得加载到内存，Hadoop也是如此，
只不过Spark支持将需要反复用到的数据给Cache到内存中，减少数据加载耗时，所以Spark跑机器学习算法比较在行（需要对数据进行反复迭代）

Spark和MapReduce的计算都发生在内存中。
MapReduce需要将每次计算的结果写入磁盘，然后再从磁盘读取数据，从而导致了频繁的磁盘IO。Spark通常不需要将计算的结果写入磁盘，
可以在内存中进行迭代计算。这得益于Spark的RDD和DAG（有向无环图），其中DAG记录了job的stage以及在job执行过程中父RDD和子RDD之间的依赖关系。
中间结果能够以RDD的形式存放在内存中，极大减少了磁盘IO。

MapReduce在Shuffle时需要花费大量时间进行排序，排序在MapReduce的Shuffle中似乎是不可避免的；
Spark在Shuffle时则只有部分场景才需要排序，支持基于Hash的分布式聚合，更加省时；







【】Standalone模式（也依赖于机群）
Standalone client
    程序Driver运行在本地，服务会注册到master机群，Master根据submit脚本的资源需求找到内部资源至少可以启动一个Executor的所有Worker，
    然后在这些Worker之间分配Executor，Worker上的Executor启动后会向Driver反向注册，所有的Executor注册完成后，
    Driver开始执行main函数，之后执行到Action算子时，开始划分stage，每个stage生成对应的taskSet，之后将task分发到各个Executor上执行。
Standalone Cluster
    程序Driver运行在master指定的一个Worker上，任务拆分之后也是运行在注册的Worker上的Executor中。

【】Mesoses,Yarn
    Mesoses,Yarn这俩模式一样，都是用于分发和资源管理任务。

/**
 * master=local：表示单机本地运行
 * master=local[4]：表示单机本地4核运行
 * master=spark://master:7077：表示在一个spark standalone cluster 上运行
 */