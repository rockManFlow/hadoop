【】Spark与MapReduce区别
MapReduce：基于磁盘进行计算，中间计算的结果都是存储在磁盘中，每次计算都是从磁盘中来加载数据。
    （一次 MapReduce 运算之后,会将数据的运算结果从内存写入到磁盘中,第二次 Mapredue 运算时在从磁盘中读取数据,所以其瓶颈在2次运算间的多余 IO 消耗）
    Hadoop 的 Map 和 reduce 之间的 shuffle 需要 sort。

Spark：Spark 则是将数据一直缓存在内存中,直到计算得到最后的结果,再将结果写入到磁盘,所以多次运算的情况下, Spark 是比较快的.
    当内存不足时，可以溢出到磁盘上。

【】spark介绍
Spark 是使用 scala 实现的基于内存计算的大数据开源集群计算环境.

Spark 集群中,分为 Master 节点与 worker 节点,,其中 Master 节点上常驻 Master 守护进程和 Driver 进程,
Master 负责将串行任务变成可并行执行的任务集Tasks, 同时还负责出错问题处理等,而 Worker 节点上常驻 Worker 守护进程,
Master 节点与 Worker 节点分工不同, Master 负载管理全部的 Worker 节点,而 Worker 节点负责执行任务.

Spark 支持不同的运行模式,包括Local, Standalone,Mesoses,Yarn 模式.不同的模式可能会将 Driver 调度到不同的节点上执行.

集群管理器：
Standalone： 这个集群管理器打包在 spark 的程序里，是最简单的集群管理器
Mesoses：一个非常成熟的分布式操作系统，可以用来运行除 Spark 以外的很多系统。
Yarn：Hadoop 的 资源管理器。

ps:
运行程序前得安装spark环境，由于是使用Scala编写的，仅是提供了java API的接口，具体的执行还是得Scala程序来运行，因此需要先安装。---验证不安装也可以本地运行


【】运行方式
方式1：spark-submit --class com.xxxx.App xxxxx.jar --master local[3]  --验证OK

【】SparkSQL
SparkSQL可以理解为在原生的RDD上做的一层封装，通过SparkSQL可以在scala和java中写SQL语句，Spark SQL也可以用来从Hive中读取数据，
并将结果作为Dataset/DataFrame返回。简单来讲，SparkSQL可以让我们像写SQL一样去处理内存中的数据。
它是用来处理结构化的数据，例如具有schema结构的数据，json, parquet, avro, csv格式的。
比如txt的等非格式化数据可以通过spark转成指定格式化的数据，再通过sql进行查询。

通过spark sql ，可以使用SQL 或者 HQL 来查询数据，查询结果以Dataset/DataFrame 的形式返回
它支持多种数据源，如Hive 表、Parquet 以及 JSON 等
它支持开发者将SQL 和传统的RDD 变成相结合

产生背景
我们可以直接通过写sql来分析大数据中的数据。
hive是把sql翻译成mapreduce作业，mapreduce执行效率是不高的（当数据量比较大，执行时间可能十几个小时）


【问题】
1、mp和spark在各个环境如何来运行--本地、机群等方式
    spark机群模式运行原理及一个任务如何来执行？？
    yarn模式具体操作？？
2、好的场景使用spark来构建项目？
3、spark等计算框架原理思考贯通？
4、spark从hdfs或者hive或hbase上来获取数据？



【】为什么Spark比MapReduce快？
Spark计算比MapReduce快的根本原因在于DAG计算模型。（DAG实际是一个RDD关系图），DAG相比Hadoop的MapReduce在大多数情况下可以减少shuffle（洗牌）次数-比如数据转换等。
Spark是基于内存的计算，所以快，这也不是主要原因，要对数据做计算，必然得加载到内存，Hadoop也是如此，
只不过Spark支持将需要反复用到的数据给Cache到内存中，减少数据加载耗时，所以Spark跑机器学习算法比较在行（需要对数据进行反复迭代）

Spark和MapReduce的计算都发生在内存中。
MapReduce需要将每次计算的结果写入磁盘，然后再从磁盘读取数据，从而导致了频繁的磁盘IO。Spark通常不需要将计算的结果写入磁盘，
可以在内存中进行迭代计算。这得益于Spark的RDD和DAG（有向无环图），其中DAG记录了job的stage以及在job执行过程中父RDD和子RDD之间的依赖关系。
中间结果能够以RDD的形式存放在内存中，极大减少了磁盘IO。

MapReduce在Shuffle时需要花费大量时间进行排序，排序在MapReduce的Shuffle中似乎是不可避免的；
Spark在Shuffle时则只有部分场景才需要排序，支持基于Hash的分布式聚合，更加省时；







【】Standalone模式（也依赖于机群）
Standalone client
    程序Driver运行在本地，服务会注册到master机群，Master根据submit脚本的资源需求找到内部资源至少可以启动一个Executor的所有Worker，
    然后在这些Worker之间分配Executor，Worker上的Executor启动后会向Driver反向注册，所有的Executor注册完成后，
    Driver开始执行main函数，之后执行到Action算子时，开始划分stage，每个stage生成对应的taskSet，之后将task分发到各个Executor上执行。
Standalone Cluster
    程序Driver运行在master指定的一个Worker上，任务拆分之后也是运行在注册的Worker上的Executor中。

【】Mesoses,Yarn
    Mesoses,Yarn这俩模式一样，都是用于分发和资源管理任务。

/**
 * master=local：表示单机本地运行
 * master=local[4]：表示单机本地4核运行
 * master=spark://master:7077：表示在一个spark standalone cluster 上运行
 */


 【】spark中哪些操作可以并行运行，哪些是聚合串行运行
 *并行运行的操作类型包括但不限于：
 map：对RDD中的每个元素应用一个函数。
 flatMap：类似于map，但每个输入元素可以映射到多个输出元素。
 filter：对RDD中的元素进行过滤。
 union：对两个RDD进行合并。
 join：当RDD是(K,V)和(K,W)类型时，对它们按键进行连接。
 groupByKey：当RDD是(K,V)类型时，对键进行分组。
 reduceByKey：当RDD是(K,V)类型时，对每个键的值进行规约。
 sortByKey：当RDD是(K,V)类型时，对键进行排序。

 *聚合串行运行



spark中操作属于惰性执行，只有遇到动作才会真正执行。

操作
map：对RDD中的每个元素应用指定的函数，并返回一个新的RDD。
filter：根据指定的条件过滤RDD中的元素，返回一个新的RDD，其中只包含满足条件的元素。
flatMap：类似于map，但可以将每个元素映射为多个元素（即返回一个迭代器），并将结果合并为一个新的RDD。
mapPartitions：与map类似，但作用于RDD的分区级别，对每个分区应用指定的函数。
sample：根据指定的比例和是否有放回抽样，对RDD进行抽样，并返回一个新的RDD。
union：将两个或多个RDD合并为一个新的RDD，包含所有RDD中的元素。注意，如果RDD中有重复元素，它们也会被包含在新RDD中。
distinct：返回一个新的RDD，其中只包含原RDD中的唯一元素。
groupByKey：对键值对RDD中的元素进行分组，返回一个新的RDD，其中每个键对应一个值的序列。
reduceByKey：对键值对RDD中的元素进行聚合操作，使用指定的函数对具有相同键的值进行合并。
sortByKey：对键值对RDD中的元素按键进行排序，并返回一个新的RDD。
join：对两个键值对RDD进行连接操作，返回一个新的RDD，其中每个键对应一个包含两个值的元组（分别来自两个RDD）。
cogroup：对两个键值对RDD进行分组操作，返回一个新的RDD，其中每个键对应两个值的序列（分别来自两个RDD）。
cartesian：对两个RDD进行笛卡尔积操作，返回一个新的RDD，其中每个元素是一个包含两个元素的元组（分别来自两个RDD的一个元素）。
coalesce：减少RDD的分区数量。
repartition：重新分区RDD，使其分区数量达到指定的数量，并可能触发数据混洗。


Action（动作）
reduce：通过指定的函数对RDD中的元素进行聚合操作，并返回聚合后的结果。
collect：将RDD中的所有元素收集到驱动程序中，并返回一个数组。注意，这可能会导致驱动程序内存溢出。
count：返回RDD中元素的数量。
first：返回RDD中的第一个元素。
take：返回RDD中的前n个元素。
foreach：对RDD中的每个元素应用指定的函数，但不返回结果。--并行执行
countByKey：返回键值对RDD中每个键对应的元素数量。
saveAsTextFile：将RDD的内容保存为文本文件。
saveAsSequenceFile：将键值对RDD的内容保存为Hadoop的SequenceFile格式。
saveAsObjectFile：将RDD的内容保存为Java序列化的文件。