#mapReduce计算规则
1、map---首先执行
映射阶段的任务是计算输入分割出现每个单词的数量

2、reduce
https://cloud.tencent.com/developer/article/1010720


【】实时数据采集和传输最为常用的则是 Flume 和 Kafka
( 1 ) Sqoop
Sqoop 作为一款开源的离线数据传输工具，主要用于 Hadoop ( Hive ）与传统数据库（ MySQL PostgreSQL 等）间的数据传递。
( 2 ）Flume
Flume Cloudera 提供的一个高可用、高可靠、分布式的海量日志采集、聚合和传输的系统，目前已经是 Apache 的顶级子项目 使用 Flume 可以收集诸如日志、时间等数据，并将这些数据资源集中存储起来供下游使用（尤其是流处理框架，例如 Storm ）。

【】分析工具
Hive：建立在Hadoop 体系结构上的一层 SQL 抽象。主流离线数据处理工具。 数据仓库工具：可以接收sql，翻译成mapreduce或者spark程序运行。
MapReduce、Hive 只支持批处理任务
spark：批处理
Spark Streaming：流式处理（准实时-0.5到2秒处理速度）
spark sql:
Flink：流式处理
storm：只支持流处理任务(实时)。--Storm 目前最小的延迟是100ms 左右

【】存储
hdfs:
HBase:

